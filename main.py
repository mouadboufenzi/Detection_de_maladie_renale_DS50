import streamlit as st
import pandas as pd
from io import StringIO, BytesIO
import joblib
from sklearn.model_selection import train_test_split

from src.load_data      import load_dataset                 # raw CSV loader
from src.cleaning       import clean_data                   # full cleaning / imputation
from src.explore_data   import show_missing_data, plot_distributions, show_pairplot
from src.visualize_data import show_correlation_matrix, plot_boxplots
from src.model_training import compare_models_with_cv, plot_heatmap
from src.model_evaluation import evaluate_model_on_test, plot_confusion

st.set_page_config(page_title="CKD Detection", layout="wide")
st.title("ğŸ”¬ Chronic Kidney Disease Detection")

st.write(
    "This interactive app walks through the entire pipeline of predicting Chronic "
    "Kidney Disease (CKD) â€” from raw CSV to a downloadable trained model."
)

# 1. Upload raw data 
st.markdown("### ğŸ“ Step 1 â€“ Upload CKD dataset (CSV)")
uploaded_file = st.file_uploader("Upload the dataset", type=["csv"])


# helper: convert DataFrame to CSV string (for download button)
def _df_to_csv(df: pd.DataFrame) -> str:
    buf = StringIO()
    df.to_csv(buf, index=False)
    return buf.getvalue()


# Main workflow starts after file upload
if uploaded_file:

    # 1-A â€¢ Load raw data
    raw_df = load_dataset(uploaded_file)
    st.success("âœ… Dataset loaded")
    st.dataframe(raw_df.head())

    st.markdown("#### Missing-value overview (raw)")
    show_missing_data(raw_df)

    # 2 â€¢ Cleaning / Imputation
    st.markdown("### ğŸ§¹ Step 2 â€“ Data cleaning")
    clean_df = clean_data(raw_df)
    st.success("âœ… Cleaning completed")
    st.dataframe(clean_df.head())

    # 3 â€¢ Quick EDA  (still on cleaned data)
    st.markdown("### ğŸ“Š Step 3 â€“ Exploratory Data Analysis")
    plot_distributions(clean_df, cols_per_row=4)
    plot_boxplots(clean_df, cols_per_row=4)
    show_pairplot(clean_df)
    show_correlation_matrix(clean_df)

    # 4 â€¢ Train / test split  (NO transformation done yet)
    st.markdown("### âœ‚ï¸ Step 4 â€“ Train / Test split (80 / 20)")
    X_full = clean_df.drop(columns=["classification"])
    y_full = clean_df["classification"]

    X_train, X_test, y_train, y_test = train_test_split(
        X_full, y_full, test_size=0.20, stratify=y_full, random_state=42
    )
    st.write(f"Training set : {X_train.shape}â€ƒâ€ƒTest set : {X_test.shape}")

    # 5 â€¢ Model comparison via leakage-free Pipelines (CV)
    st.markdown("### ğŸ¤– Step 5 â€“ Model comparison (5-fold CV on training set)")

    results_df, model_dict = compare_models_with_cv(X_train, y_train)
    st.dataframe(results_df.style.format(precision=4))
    st.pyplot(plot_heatmap(results_df))

    # 6 â€¢ Evaluation on held-out test set + confusion matrices
    st.markdown("### ğŸ” Step 6 â€“ Confusion matrices on the 20 % test set")

    for name, pipe in model_dict.items():
        pipe.fit(X_train, y_train)                       # fit on training set only
        eval_res = evaluate_model_on_test(pipe, X_test, y_test)
        st.subheader(f"Confusion Matrix â€” {name}")
        st.pyplot(plot_confusion(eval_res["Confusion Matrix"]))

    # 7 â€¢ Highlight best model metrics
    best_model_name = results_df["Accuracy"].idxmax()
    best_pipe = model_dict[best_model_name].fit(X_train, y_train)
    best_eval = evaluate_model_on_test(best_pipe, X_test, y_test)

    st.markdown("### ğŸ† Step 7 â€“ Best model performance on Test set")
    for k in ["Accuracy", "ROC AUC", "Precision", "Recall"]:
        st.write(f"**{k}** : {best_eval[k]:.4f}")
    st.json(best_eval["Classification Report"])

    # 8 â€¢ Download trained pipeline
    st.markdown("### ğŸ’¾ Step 8 â€“ Download trained pipeline")
    bytes_buf = BytesIO()
    joblib.dump(best_pipe, bytes_buf)
    bytes_buf.seek(0)
    st.download_button(
        label="â¬‡ï¸ Download pipeline (.joblib)",
        data=bytes_buf,
        file_name=f"ckd_{best_model_name.lower().replace(' ', '_')}_pipeline.joblib",
        mime="application/octet-stream",
    )

    # 9 â€¢ Optional â€“ download the cleaned train / test splits
    st.markdown("### ğŸ“„ Optional â€“ Download cleaned splits")
    st.download_button("â¬‡ï¸ Train CSV", _df_to_csv(pd.concat([X_train, y_train], axis=1)),
                       file_name="train_clean.csv")
    st.download_button("â¬‡ï¸ Test  CSV", _df_to_csv(pd.concat([X_test,  y_test],  axis=1)),
                       file_name="test_clean.csv")
