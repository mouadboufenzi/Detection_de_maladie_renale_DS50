import streamlit as st
import pandas as pd
from io import StringIO, BytesIO
import joblib
from sklearn.model_selection import train_test_split

from src.load_data import load_dataset
from src.cleaning import DataCleaner
from src.explore_data import show_missing_data, plot_distributions, show_pairplot
from src.visualize_data import show_correlation_matrix, plot_boxplots, plot_pca_projection
from src.model_training import compare_models_with_cv, plot_heatmap
from src.model_evaluation import evaluate_model_on_test, plot_confusion

st.set_page_config(page_title="CKD Detection", layout="wide")
st.title("ğŸ”¬ Chronic Kidney Disease Detection")

st.write(
    "This interactive app walks through the entire pipeline of predicting Chronic "
    "Kidney Disease (CKD) - from raw CSV to a downloadable trained model."
)

# 1 â”€ Upload raw data --------------------------------------------------------
st.markdown("### ğŸ“ Step 1 â€“ Upload CKD dataset (CSV)")
uploaded_file = st.file_uploader("Upload the dataset", type=["csv"])

def _df_to_csv(df: pd.DataFrame) -> str:
    buf = StringIO()
    df.to_csv(buf, index=False)
    return buf.getvalue()

if uploaded_file:
    # 1-A â€¢ Load raw data
    raw_df = load_dataset(uploaded_file)
    st.success("âœ… Dataset loaded")
    st.dataframe(raw_df.head())

    st.markdown("#### Missing-value overview (raw)")
    show_missing_data(raw_df)

    # 2 â”€ Train / Test split --------------------------------------------------
    st.markdown("### âœ‚ï¸ Step 2 â€“ Train / Test split (80 / 20)")
    if "classification" not in raw_df.columns:
        st.error("Dataset must contain 'classification' column")
        st.stop()

    X_full = raw_df.drop(columns=["classification"])
    y_full = raw_df["classification"]

    X_train, X_test, y_train, y_test = train_test_split(
        X_full,
        y_full,
        test_size=0.20,
        stratify=y_full,
        random_state=42,
    )

    # create train_df and test_df
    train_df = pd.concat([X_train, y_train], axis=1)
    test_df = pd.concat([X_test, y_test], axis=1)

    st.write(f"Raw training set : {train_df.shape}â€ƒâ€ƒRaw test set : {test_df.shape}")

    # 3 â”€ Quick EDA on Raw Data (Before Cleaning) ----------------------------
    st.markdown("### ğŸ“Š Step 3 â€“ EDA on Raw Training Data (Pre-Cleaning)")
    plot_distributions(train_df, cols_per_row=4)
    plot_boxplots(train_df, cols_per_row=4)
    show_pairplot(train_df)
    show_correlation_matrix(train_df)

    # 4 â”€ Data cleaning (no leakage) -----------------------------------------
    st.markdown("### ğŸ§¹ Step 4 â€“ Data cleaning (no leakage)")
    cleaner = DataCleaner()
    clean_train = cleaner.fit_transform(train_df)
    clean_test = cleaner.transform(test_df)

    st.success("âœ… Cleaning completed")
    st.dataframe(clean_train.head())

    # # 5 â”€ Optional: EDA on Cleaned Data --------------------------------------
    # st.markdown("### ğŸ“Š Step 5 â€“ EDA on Cleaned Training Data (Post-Cleaning)")
    # plot_distributions(clean_train, cols_per_row=4)
    # plot_boxplots(clean_train, cols_per_row=4)
    # show_pairplot(clean_train)
    # show_correlation_matrix(clean_train)

    st.markdown("#### PCA Projection (Cleaned Data)")
    pca_fig = plot_pca_projection(clean_train)
    if pca_fig:
        st.pyplot(pca_fig)

    # 5 â”€ Prepare ML Features -------------------------------------------------
    st.markdown("### âœ‚ï¸ Step 5 â€“ Prepare ML Features")
    X_train_clean = clean_train.drop(columns=["classification"])
    y_train_clean = clean_train["classification"]
    X_test_clean  = clean_test.drop(columns=["classification"])
    y_test_clean  = clean_test["classification"]

    # 6 â”€ Model comparison ----------------------------------------------------
    st.markdown("### ğŸ¤– Step 6 â€“ Model comparison (5-fold CV on training set)")
    use_pca     = st.checkbox("Enable PCA Dimensionality Reduction", value=False)
    n_components = st.slider("PCA Components", 2, 5, 2) if use_pca else 2

    results_df, model_dict = compare_models_with_cv(
        X_train_clean, y_train_clean,
        use_pca=use_pca, n_components=n_components,
    )

    st.dataframe(results_df.style.format(precision=4))
    st.pyplot(plot_heatmap(results_df))

    # 7 â”€ Test set evaluation -------------------------------------------------
    if results_df.empty:
        st.warning("No model produced valid cross-validation results â€“ "
                "please inspect the previous error messages.")
        st.stop()
    st.markdown("### ğŸ” Step 7 â€“ Confusion matrices on the 20% test set")
    for name, pipe in model_dict.items():
        pipe.fit(X_train_clean, y_train_clean)
        eval_res = evaluate_model_on_test(pipe, X_test_clean, y_test_clean)
        st.subheader(f"Confusion Matrix â€“ {name}")
        st.pyplot(plot_confusion(eval_res["Confusion Matrix"]))

    # 8 â”€ Cross-validation top performer metrics ---------------------------------
    st.markdown("### ğŸ† Step 8 â€“ Performance of the best generalizing model (CV Top Performer)")

    # Obtain the best performing model name from the cross validation results
    best_model_name = results_df["Accuracy"].idxmax()
    st.write(f"ğŸ” Based on cross-validation, the best generalizing model is: **{best_model_name}**")

    best_pipe = model_dict[best_model_name].fit(X_train_clean, y_train_clean)

    best_eval = evaluate_model_on_test(best_pipe, X_test_clean, y_test_clean)

    for k in ["Accuracy", "ROC AUC", "Precision", "Recall"]:
        st.write(f"**{k}** : {best_eval[k]:.4f}")

    # JSON
    st.markdown("#### ğŸ“‹ Detailed Classification Report")
    st.json(best_eval["Classification Report"])


    # 9 â”€ Download trained pipeline ------------------------------------------
    st.markdown("### ğŸ’¾ Step 9 â€“ Download trained pipeline")
    bytes_buf = BytesIO()
    joblib.dump(best_pipe, bytes_buf)
    bytes_buf.seek(0)
    st.download_button(
        label="â¬‡ï¸ Download pipeline (.joblib)",
        data=bytes_buf,
        file_name=f"ckd_{best_model_name.lower().replace(' ', '_')}_pipeline.joblib",
        mime="application/octet-stream",
    )

    # 10 â”€ Optional data download --------------------------------------------
    st.markdown("### ğŸ“„ Optional â€“ Download cleaned splits")
    st.download_button("â¬‡ï¸ Train CSV", _df_to_csv(clean_train),
                       file_name="train_clean.csv")
    st.download_button("â¬‡ï¸ Test CSV", _df_to_csv(clean_test),
                       file_name="test_clean.csv")
